import os
import streamlit as st
import pandas as pd
import time
import sys

# --- 1. í˜ì´ì§€ ê¸°ë³¸ ì„¤ì • (ê°€ì¥ ë¨¼ì € í˜¸ì¶œ) ---
st.set_page_config(
    page_title="ì„¸ë´‡ì´ ğŸ¤–",
    page_icon="ğŸ§¾",
    layout="centered",
)

# --- 2. ê¸°ë³¸ ì„¤ì • ë° ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ---
# ChromaDB ì‚¬ìš©ì„ ìœ„í•œ pysqlite3 ì„¤ì • (Streamlit Cloud ë°°í¬ ì‹œ í•„ìš”)
if sys.version_info.major == 3 and sys.version_info.minor >= 10:
    try:
        __import__('pysqlite3')
        sys.modules['sqlite3'] = sys.modules.get('pysqlite3')
    except ImportError:
        pass

from langchain_community.document_loaders import PyPDFLoader, UnstructuredFileLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain_chroma import Chroma
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables import RunnablePassthrough
from langchain_core.output_parsers import StrOutputParser
from langchain.agents import AgentExecutor, create_tool_calling_agent
from langchain.tools import tool
from langchain.tools.retriever import create_retriever_tool
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.messages import HumanMessage, AIMessage

# --- 3. API í‚¤ ì„¤ì • (ë³´ì•ˆ ê°•í™”) ---
try:
    # Streamlit Secretsì—ì„œ API í‚¤ ë¡œë“œ
    os.environ["OPENAI_API_KEY"] = st.secrets["OPENAI_API_KEY"]
    # Tavily Search API í‚¤ (ì›¹ ê²€ìƒ‰ ë„êµ¬ìš©, ì„ íƒ ì‚¬í•­)
    os.environ["TAVILY_API_KEY"] = st.secrets["TAVILY_API_KEY"]
except (KeyError, FileNotFoundError):
    st.error("ğŸš¨ API í‚¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. .streamlit/secrets.toml íŒŒì¼ì— í‚¤ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.")
    st.stop()


# --- 4. LangChain ë°±ì—”ë“œ í•¨ìˆ˜ ---
@tool
def calculator(expression: str) -> str:
    """
    ì‚¬ìš©ìë¡œë¶€í„° ë°›ì€ ìˆ˜í•™ì  í‘œí˜„ì‹ì„ ê³„ì‚°í•©ë‹ˆë‹¤.
    ì´ ë„êµ¬ëŠ” ë§ì…ˆ, ëº„ì…ˆ, ê³±ì…ˆ, ë‚˜ëˆ—ì…ˆ ë“± ê¸°ë³¸ì ì¸ ì‚¬ì¹™ì—°ì‚°ì„ ì²˜ë¦¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    ì˜ˆì‹œ: "35000 * 0.1" ë˜ëŠ” "10000 + 2500"
    """
    try:
        # ê²½ê³ : eval()ì€ ì•ˆì „í•˜ì§€ ì•Šì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì‹¤ì œ í”„ë¡œë•ì…˜ì—ì„œëŠ”
        #      ë” ì•ˆì „í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬(ì˜ˆ: numexpr) ì‚¬ìš©ì„ ê¶Œì¥í•©ë‹ˆë‹¤.
        result = eval(expression)
        return f"ê³„ì‚° ê²°ê³¼: {result}"
    except Exception as e:
        return f"ê³„ì‚° ì˜¤ë¥˜: {e}"

@st.cache_resource
def load_and_split_documents(file_paths):
    """ì—¬ëŸ¬ íŒŒì¼ì„ ë¡œë“œí•˜ê³  ë¶„í• í•˜ëŠ” í•¨ìˆ˜"""
    all_pages = []
    for file_path in file_paths:
        if file_path.endswith('.pdf'):
            loader = PyPDFLoader(file_path)
            all_pages.extend(loader.load_and_split())
        else:
            loader = UnstructuredFileLoader(file_path)
            all_pages.extend(loader.load_and_split())
    return all_pages

@st.cache_resource
def get_vectorstore(_docs):
    """ë¬¸ì„œë“¤ë¡œë¶€í„° ë²¡í„° ì €ì¥ì†Œë¥¼ ìƒì„±í•˜ê±°ë‚˜ ë¡œë“œí•˜ëŠ” í•¨ìˆ˜"""
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)
    split_docs = text_splitter.split_documents(_docs)
    
    vectorstore = Chroma.from_documents(
        documents=split_docs,
        embedding=OpenAIEmbeddings(model='text-embedding-3-small')
    )
    return vectorstore

def format_docs(docs):
    """ê²€ìƒ‰ëœ ë¬¸ì„œë“¤ì„ í•˜ë‚˜ì˜ ë¬¸ìì—´ë¡œ í¬ë§·í•˜ëŠ” í•¨ìˆ˜"""
    return "\n\n".join(doc.page_content for doc in docs)

@st.cache_resource
def get_retriever():
    """ë¬¸ì„œë¡œë¶€í„° retrieverë¥¼ ìƒì„±í•˜ëŠ” í•¨ìˆ˜ (RAG ë„êµ¬ì˜ ê¸°ë°˜)"""
    try:
        base_docs_paths = [
            os.path.join("data", "2025.1ê¸° í™•ì • ë¶€ê°€ê°€ì¹˜ì„¸ ì‹ ê³ ì•ˆë‚´ ë§¤ë‰´ì–¼.pdf"),
            os.path.join("data", "2024ë…„ ì œ2ê¸° í™•ì • ë¶€ê°€ê°€ì¹˜ì„¸ ì‹ ê³ ì•ˆë‚´.pdf"),
            os.path.join("data", "ë¶€ê°€ê°€ì¹˜ì„¸_êµ­ì„¸ì²­_ìœ ê¶Œí•´ì„ì‚¬ë¡€.pdf"),
            os.path.join("data", "ë¶€ê°€ê°€ì¹˜ì„¸_ì‹¤ë¬´ì‚¬ë¡€.pdf"),
            os.path.join("data", "ë¶€ê°€ì„¸ ì‹ ê³ í•  ë•Œ ìì£¼ ë¬»ëŠ” ì§ˆë¬¸ë“¤_í† ìŠ¤í˜ì´ë¨¼ì¸ .pdf")
        ]
        
        all_pages = []
        for file_path in base_docs_paths:
            loader = PyPDFLoader(file_path)
            all_pages.extend(loader.load_and_split())

        text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)
        split_docs = text_splitter.split_documents(all_pages)
        
        vectorstore = Chroma.from_documents(
            documents=split_docs,
            embedding=OpenAIEmbeddings(model='text-embedding-3-small')
        )
        return vectorstore.as_retriever()
    except Exception as e:
        st.error(f"ğŸš¨ ê¸°ë³¸ PDF ë¬¸ì„œë¥¼ ë¡œë“œí•˜ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {e}")
        st.info("'data' í´ë”ì— PDF íŒŒì¼ì´ ìˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
        st.stop()

@st.cache_resource
def build_agent_executor():
    """í•„ìš”í•œ ë„êµ¬ë“¤ì„ í¬í•¨í•œ ì—ì´ì „íŠ¸ ì‹¤í–‰ê¸°ë¥¼ ë¹Œë“œí•©ë‹ˆë‹¤."""
    
    llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)
    
    # --- [ë„êµ¬ 2] RAG ê²€ìƒ‰ ë„êµ¬ ìƒì„± ---
    retriever = get_retriever()
    retriever_tool = create_retriever_tool(
        retriever,
        "vat_law_search", # ë„êµ¬ ì´ë¦„
        "ëŒ€í•œë¯¼êµ­ ë¶€ê°€ê°€ì¹˜ì„¸(VAT) ë²•ë¥ , ê·œì •, ì‹ ê³  ì ˆì°¨ì— ëŒ€í•œ ì •ë³´ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤. ì„¸ê¸ˆ ìš©ì–´, ì‹ ê³  ê¸°í•œ, ê³µì œ í•­ëª© ë“±ì— ëŒ€í•œ ì§ˆë¬¸ì— ì‚¬ìš©í•˜ì„¸ìš”." # ë„êµ¬ ì„¤ëª…
    )
    
    # --- [ë„êµ¬ 3] ì›¹ ê²€ìƒ‰ ë„êµ¬ (ì„ íƒ ì‚¬í•­) ---
    # ìµœì‹  ì •ë³´ë¥¼ ìœ„í•´ ì›¹ ê²€ìƒ‰ì´ í•„ìš”í•  ê²½ìš° ì‚¬ìš©
    web_search_tool = TavilySearchResults(max_results=2)

    # ì—ì´ì „íŠ¸ê°€ ì‚¬ìš©í•  ë„êµ¬ ë¦¬ìŠ¤íŠ¸
    tools = [calculator, retriever_tool, web_search_tool]

    # ì—ì´ì „íŠ¸ í”„ë¡¬í”„íŠ¸ ì„¤ì •
    # LLMì´ ë„êµ¬ë¥¼ ì–´ë–»ê²Œ ì‚¬ìš©í• ì§€, ì–´ë–¤ ì—­í• ì„ í• ì§€ ì§€ì‹œí•©ë‹ˆë‹¤.
    prompt = ChatPromptTemplate.from_messages([
        ("system", """
        ë‹¹ì‹ ì€ ì „ë¬¸ ì„¸ë¬´ ìƒë‹´ì‚¬ AI ì—ì´ì „íŠ¸ 'ì„¸ë´‡ì´'ì…ë‹ˆë‹¤.
        ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë‹µë³€í•˜ê¸° ìœ„í•´ ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ë“¤ì„ ì ê·¹ì ìœ¼ë¡œ í™œìš©í•´ì•¼ í•©ë‹ˆë‹¤.
        ì´ì „ ëŒ€í™” ë‚´ìš©ì„ ì°¸ê³ í•˜ì—¬ ë§¥ë½ì— ë§ëŠ” ë‹µë³€ì„ í•˜ì„¸ìš”.

        - **vat_law_search**: ë¶€ê°€ê°€ì¹˜ì„¸ ë²•ë¥ , ê·œì •, ì ˆì°¨ì— ëŒ€í•œ ì§ˆë¬¸ì¼ ë•Œ ì‚¬ìš©í•˜ì„¸ìš”.
        - **calculator**: ìˆ«ì ê³„ì‚°ì´ í•„ìš”í•  ë•Œ ì‚¬ìš©í•˜ì„¸ìš”.
        - **tavily_search_results_json**: ìµœì‹  ì •ë³´ë‚˜ ë²•ë¥  ì™¸ ì¼ë°˜ ì •ë³´ê°€ í•„ìš”í•  ë•Œ ì‚¬ìš©í•˜ì„¸ìš”.
        
        ë‹µë³€ì€ í•­ìƒ í•œêµ­ì–´ë¡œ, ì¹œì ˆí•˜ê³  ëª…í™•í•˜ê²Œ ì œê³µí•´ì•¼ í•©ë‹ˆë‹¤.
        """),
        MessagesPlaceholder(variable_name="chat_history", optional=True),
        ("human", "{input}"),
        MessagesPlaceholder(variable_name="agent_scratchpad"),
    ])

    agent = create_tool_calling_agent(llm, tools, prompt)
    agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)
    
    return agent_executor


# --- [ì¶”ê°€] ëŒ€í™” ê¸°ë¡ì„ ë¬¸ìì—´ë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜ ---
def format_chat_history(messages):
    """ì„¸ì…˜ì˜ ëŒ€í™” ê¸°ë¡ì„ LLMì— ì „ë‹¬í•  í˜•ì‹ì˜ ë¬¸ìì—´ë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
    if not messages:
        return ""
    # ë§ˆì§€ë§‰ 6ê°œ ë©”ì‹œì§€ (3ìŒì˜ ì§ˆë¬¸/ë‹µë³€)ë¥¼ ì»¨í…ìŠ¤íŠ¸ë¡œ ì‚¬ìš©
    history = []
    for msg in messages[-6:]:
        role = "ì‚¬ìš©ì" if msg["role"] == "user" else "ì±—ë´‡"
        history.append(f"{role}: {msg['content']}")
    return "\n".join(history)

# --- 5. ë©”ì¸ ë¡œì§ ---
agent_executor = build_agent_executor()

# --- ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” ---
if "messages" not in st.session_state:
    st.session_state.messages = []
if "file_context" not in st.session_state:
    st.session_state.file_context = None
if "file_name" not in st.session_state:
    st.session_state.file_name = None

# --- ì‚¬ì´ë“œë°” UI êµ¬ì„± ---
with st.sidebar:
    st.title("ğŸ§¾ íŒŒì¼ ì—…ë¡œë“œ")
    st.info("ì„¸ê¸ˆê³„ì‚°ì„œ(XLSX, CSV)ë‚˜ ê´€ë ¨ PDF íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì—¬ ì§ˆë¬¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

    uploaded_file = st.file_uploader(
        "íŒŒì¼ì„ ì„ íƒí•˜ì„¸ìš”.",
        type=['xlsx', 'csv', 'pdf'],
        label_visibility="collapsed"
    )

    if uploaded_file:
        try:
            file_name = uploaded_file.name
            df = None
            
            if file_name.endswith('.xlsx'):
                df = pd.read_excel(uploaded_file)
            elif file_name.endswith('.csv'):
                df = pd.read_csv(uploaded_file)
            elif file_name.endswith('.pdf'):
                st.warning("PDF íŒŒì¼ì€ í˜„ì¬ ë¯¸ë¦¬ë³´ê¸°ë¥¼ ì§€ì›í•˜ì§€ ì•Šì§€ë§Œ, ë‚´ìš©ì— ëŒ€í•œ ì§ˆë¬¸ì€ ê°€ëŠ¥í•©ë‹ˆë‹¤.")
                st.session_state.file_name = file_name
                st.session_state.file_context = "PDF íŒŒì¼ì´ ì—…ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤. íŒŒì¼ ë‚´ìš©ì— ëŒ€í•´ ì§ˆë¬¸í•´ì£¼ì„¸ìš”."
            
            if df is not None:
                st.session_state.file_context = df.to_markdown()
                st.session_state.file_name = file_name
                st.subheader("âœ… ì—…ë¡œë“œ íŒŒì¼ ë¯¸ë¦¬ë³´ê¸°")
                st.dataframe(df, height=300, use_container_width=True)

        except Exception as e:
            st.error(f"íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            st.session_state.file_context = None
            st.session_state.file_name = None
    
    if st.session_state.file_name:
        if st.button("ğŸ”„ ì—…ë¡œë“œ íŒŒì¼ ì´ˆê¸°í™”", use_container_width=True):
            st.session_state.file_context = None
            st.session_state.file_name = None
            st.success("íŒŒì¼ì´ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤. ì¼ë°˜ ì§ˆë¬¸ ëª¨ë“œë¡œ ì „í™˜í•©ë‹ˆë‹¤.")
            time.sleep(1)
            st.rerun()

# --- ë©”ì¸ í™”ë©´ UI êµ¬ì„± ---
st.title("ì„¸ë´‡ì´ ğŸ¤–")
st.write("ë¶€ê°€ê°€ì¹˜ì„¸ ê´€ë ¨ ì§ˆë¬¸ì— ë‹µë³€í•´ ë“œë¦½ë‹ˆë‹¤. ì™¼ìª½ ì‚¬ì´ë“œë°”ì— íŒŒì¼ì„ ì˜¬ë ¤ íŠ¹ì • ë¬¸ì„œì— ëŒ€í•´ ì§ˆë¬¸í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤.")
st.write("---")

if st.session_state.file_name:
    st.info(f"ğŸ§¾ **'{st.session_state.file_name}' íŒŒì¼ì— ëŒ€í•´ ì§ˆë¬¸í•©ë‹ˆë‹¤.**")
else:
    st.info("ğŸ’¡ **ì¼ë°˜ ë¶€ê°€ê°€ì¹˜ì„¸ ì§ˆë¬¸ ëª¨ë“œì…ë‹ˆë‹¤.**")

# --- ì±„íŒ… ëŒ€í™” ê¸°ë¡ í‘œì‹œ ---
if not st.session_state.messages:
    st.session_state.messages.append({"role": "assistant", "content": "ì•ˆë…•í•˜ì„¸ìš”! ë¶€ê°€ê°€ì¹˜ì„¸ì— ëŒ€í•´ ê¶ê¸ˆí•œ ì ì„ ë¬¼ì–´ë³´ì„¸ìš”."})

for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.write(msg["content"])

# --- ì˜ˆì‹œ ì§ˆë¬¸ ë²„íŠ¼ ---
if len(st.session_state.messages) <= 1:
    st.write("**ì˜ˆì‹œ ì§ˆë¬¸:**")
    cols = st.columns(3)
    example_questions = ["ê°„ì´ê³¼ì„¸ì ë¶€ê°€ì„¸ëŠ”?", "ë§¤ì…ì„¸ì•¡ê³µì œë€?", "ì„¸ê¸ˆê³„ì‚°ì„œ ë°œê¸‰ì˜ë¬´"]
    
    # ì˜ˆì‹œ ë²„íŠ¼ í´ë¦­ ì‹œ ë©”ì‹œì§€ ì¶”ê°€ ë° rerun
    if cols[0].button(example_questions[0], use_container_width=True):
        st.session_state.messages.append({"role": "user", "content": example_questions[0]})
        st.rerun()
    if cols[1].button(example_questions[1], use_container_width=True):
        st.session_state.messages.append({"role": "user", "content": example_questions[1]})
        st.rerun()
    if cols[2].button(example_questions[2], use_container_width=True):
        st.session_state.messages.append({"role": "user", "content": example_questions[2]})
        st.rerun()

# --- ì‚¬ìš©ì ì±„íŒ… ì…ë ¥ ---
if user_input := st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš” :)"):
    st.session_state.messages.append({"role": "user", "content": user_input})
    st.rerun()

# --- ì±—ë´‡ ì‘ë‹µ ìƒì„± ë¡œì§ ---
# ë§ˆì§€ë§‰ ë©”ì‹œì§€ê°€ ì‚¬ìš©ìì˜ ê²ƒì´ê³ , ì•„ì§ ë´‡ì´ ì‘ë‹µí•˜ì§€ ì•Šì•˜ì„ ê²½ìš°ì—ë§Œ ì‹¤í–‰
if st.session_state.messages and st.session_state.messages[-1]["role"] == "user":
    user_prompt = st.session_state.messages[-1]["content"]
    
    chat_history_str = format_chat_history(st.session_state.messages[:-1])
    
    file_context_str = ""
    if st.session_state.file_context:
        file_context_str = f"""
[ì²¨ë¶€ëœ íŒŒì¼ ë‚´ìš©]
{st.session_state.file_context}
---
"""
    final_prompt = f"""
{file_context_str}
[ì´ì „ ëŒ€í™” ë‚´ìš©]
{chat_history_str}
---
ìœ„ íŒŒì¼ ë‚´ìš©ê³¼ ëŒ€í™” ë§¥ë½ì„ ë°”íƒ•ìœ¼ë¡œ ì•„ë˜ ì§ˆë¬¸ì— ë‹µë³€í•´ ì£¼ì„¸ìš”.

[ì‚¬ìš©ì ì§ˆë¬¸]
{user_prompt}
"""
    agent_input = {
        "input": final_input,
        "chat_history": chat_history,
    }
    
    with st.chat_message("assistant"):
        with st.spinner("ìƒê° ì¤‘..."):
            response = agent_executor.invoke(agent_input)
            final_answer = response.get('output', 'ì˜¤ë¥˜: ë‹µë³€ì„ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.')
            
            st.session_state.messages.append({"role": "assistant", "content": final_answer})
            st.rerun()
