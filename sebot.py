import os
import streamlit as st
import pandas as pd
import time
import sys

# --- 1. í˜ì´ì§€ ê¸°ë³¸ ì„¤ì • (ê°€ì¥ ë¨¼ì € í˜¸ì¶œ) ---
st.set_page_config(
    page_title="ì„¸ë´‡ì´ ğŸ¤–",
    page_icon="ğŸ§¾",
    layout="centered",
)

# --- 2. ê¸°ë³¸ ì„¤ì • ë° ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ---
# ChromaDB ì‚¬ìš©ì„ ìœ„í•œ pysqlite3 ì„¤ì •
if sys.version_info.major == 3 and sys.version_info.minor >= 10:
    try:
        __import__('pysqlite3')
        sys.modules['sqlite3'] = sys.modules.get('pysqlite3')
    except ImportError:
        pass

from langchain_community.document_loaders import PyPDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain_chroma import Chroma
from langchain.agents import AgentExecutor, create_tool_calling_agent
from langchain.tools import tool
from langchain.tools.retriever import create_retriever_tool
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.messages import HumanMessage, AIMessage
from langchain_community.tools.tavily_search import TavilySearchResults

# --- 3. API í‚¤ ì„¤ì • (ë³´ì•ˆ ê°•í™”) ---
try:
    os.environ["OPENAI_API_KEY"] = st.secrets["OPENAI_API_KEY"]
    os.environ["TAVILY_API_KEY"] = st.secrets["TAVILY_API_KEY"]
except (KeyError, FileNotFoundError):
    st.error("ğŸš¨ API í‚¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. .streamlit/secrets.toml íŒŒì¼ì— í‚¤ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.")
    st.stop()


# --- 4. LangChain ë°±ì—”ë“œ í•¨ìˆ˜ ---

@tool
def calculator(expression: str) -> str:
    """ì‚¬ìš©ìë¡œë¶€í„° ë°›ì€ ìˆ˜í•™ì  í‘œí˜„ì‹ì„ ê³„ì‚°í•©ë‹ˆë‹¤. ë§ì…ˆ, ëº„ì…ˆ, ê³±ì…ˆ, ë‚˜ëˆ—ì…ˆ ë“± ê¸°ë³¸ì ì¸ ì‚¬ì¹™ì—°ì‚°ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤."""
    try:
        # ê²½ê³ : eval()ì€ ì•ˆì „í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ ì‹¤ì œ í”„ë¡œë•ì…˜ì—ì„œëŠ” ë” ì•ˆì „í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì‚¬ìš©ì„ ê¶Œì¥í•©ë‹ˆë‹¤.
        result = eval(expression)
        return f"ê³„ì‚° ê²°ê³¼: {result}"
    except Exception as e:
        return f"ê³„ì‚° ì˜¤ë¥˜: {e}"

@st.cache_resource
def get_retriever():
    """PDF ë¬¸ì„œë“¤ë¡œë¶€í„° retrieverë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    try:
        base_docs_paths = [
            os.path.join("data", "2025.1ê¸° í™•ì • ë¶€ê°€ê°€ì¹˜ì„¸ ì‹ ê³ ì•ˆë‚´ ë§¤ë‰´ì–¼.pdf"),
            os.path.join("data", "2024ë…„ ì œ2ê¸° í™•ì • ë¶€ê°€ê°€ì¹˜ì„¸ ì‹ ê³ ì•ˆë‚´.pdf"),
            os.path.join("data", "ë¶€ê°€ê°€ì¹˜ì„¸_êµ­ì„¸ì²­_ìœ ê¶Œí•´ì„ì‚¬ë¡€.pdf"),
            os.path.join("data", "ë¶€ê°€ê°€ì¹˜ì„¸_ì‹¤ë¬´ì‚¬ë¡€.pdf"),
            os.path.join("data", "ë¶€ê°€ì„¸ ì‹ ê³ í•  ë•Œ ìì£¼ ë¬»ëŠ” ì§ˆë¬¸ë“¤_í† ìŠ¤í˜ì´ë¨¼ì¸ .pdf")
        ]
        
        all_pages = []
        for file_path in base_docs_paths:
            loader = PyPDFLoader(file_path)
            all_pages.extend(loader.load_and_split())

        text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)
        split_docs = text_splitter.split_documents(all_pages)
        
        vectorstore = Chroma.from_documents(
            documents=split_docs,
            embedding=OpenAIEmbeddings(model='text-embedding-3-small')
        )
        return vectorstore.as_retriever()
    except Exception as e:
        st.error(f"ğŸš¨ ê¸°ë³¸ PDF ë¬¸ì„œë¥¼ ë¡œë“œí•˜ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {e}")
        st.info("'data' í´ë”ì— PDF íŒŒì¼ì´ ìˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
        st.stop()

@st.cache_resource
def build_agent_executor():
    """í•„ìš”í•œ ë„êµ¬ë“¤ì„ í¬í•¨í•œ ì—ì´ì „íŠ¸ ì‹¤í–‰ê¸°ë¥¼ ë¹Œë“œí•©ë‹ˆë‹¤."""
    
    llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)
    
    # ë„êµ¬ ì •ì˜
    retriever = get_retriever()
    retriever_tool = create_retriever_tool(
        retriever,
        "vat_law_search",
        "ëŒ€í•œë¯¼êµ­ ë¶€ê°€ê°€ì¹˜ì„¸(VAT) ë²•ë¥ , ê·œì •, ì‹ ê³  ì ˆì°¨ì— ëŒ€í•œ ì •ë³´ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤. ì„¸ê¸ˆ ìš©ì–´, ì‹ ê³  ê¸°í•œ, ê³µì œ í•­ëª© ë“±ì— ëŒ€í•œ ì§ˆë¬¸ì— ì‚¬ìš©í•˜ì„¸ìš”."
    )
    web_search_tool = TavilySearchResults(max_results=2)
    tools = [calculator, retriever_tool, web_search_tool]

    # [ìˆ˜ì •] ì—ì´ì „íŠ¸ì— ìµœì í™”ëœ í”„ë¡¬í”„íŠ¸
    prompt = ChatPromptTemplate.from_messages([
        ("system", """
        ë‹¹ì‹ ì€ ì „ë¬¸ ì„¸ë¬´ ìƒë‹´ì‚¬ AI ì—ì´ì „íŠ¸ 'ì„¸ë´‡ì´'ì…ë‹ˆë‹¤.
        ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë‹µë³€í•˜ê¸° ìœ„í•´ ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ë“¤ì„ ì ê·¹ì ìœ¼ë¡œ í™œìš©í•´ì•¼ í•©ë‹ˆë‹¤.
        ì´ì „ ëŒ€í™” ë‚´ìš©ì„ ì°¸ê³ í•˜ì—¬ ë§¥ë½ì— ë§ëŠ” ë‹µë³€ì„ í•˜ì„¸ìš”.

        - **vat_law_search**: ë¶€ê°€ê°€ì¹˜ì„¸ ë²•ë¥ , ê·œì •, ì ˆì°¨ì— ëŒ€í•œ ì§ˆë¬¸ì¼ ë•Œ ì‚¬ìš©í•˜ì„¸ìš”.
        - **calculator**: ìˆ«ì ê³„ì‚°ì´ í•„ìš”í•  ë•Œ ì‚¬ìš©í•˜ì„¸ìš”.
        - **tavily_search_results_json**: ìµœì‹  ì •ë³´ë‚˜ ë²•ë¥  ì™¸ ì¼ë°˜ ì •ë³´ê°€ í•„ìš”í•  ë•Œ ì‚¬ìš©í•˜ì„¸ìš”.
        
        ë‹µë³€ì€ í•­ìƒ í•œêµ­ì–´ë¡œ, ì¹œì ˆí•˜ê³  ëª…í™•í•˜ê²Œ ì œê³µí•´ì•¼ í•©ë‹ˆë‹¤.
        """),
        MessagesPlaceholder(variable_name="chat_history", optional=True),
        ("human", "{input}"),
        MessagesPlaceholder(variable_name="agent_scratchpad"),
    ])

    agent = create_tool_calling_agent(llm, tools, prompt)
    agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)
    
    return agent_executor

# --- 5. ë©”ì¸ ë¡œì§ ---
agent_executor = build_agent_executor()

# --- ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” ---
if "messages" not in st.session_state:
    st.session_state.messages = []
if "file_context" not in st.session_state:
    st.session_state.file_context = None
if "file_name" not in st.session_state:
    st.session_state.file_name = None

# --- ì‚¬ì´ë“œë°” UI êµ¬ì„± ---
with st.sidebar:
    st.title("ğŸ§¾ íŒŒì¼ ì—…ë¡œë“œ")
    st.info("ì„¸ê¸ˆê³„ì‚°ì„œ(XLSX, CSV)ë‚˜ ê´€ë ¨ PDF íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì—¬ ì§ˆë¬¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    uploaded_file = st.file_uploader("íŒŒì¼ì„ ì„ íƒí•˜ì„¸ìš”.", type=['xlsx', 'csv', 'pdf'], label_visibility="collapsed")
    
    if uploaded_file:
        try:
            file_name = uploaded_file.name
            df = None
            if file_name.endswith('.xlsx'):
                df = pd.read_excel(uploaded_file)
            elif file_name.endswith('.csv'):
                df = pd.read_csv(uploaded_file)
            
            if df is not None:
                st.session_state.file_context = df.to_markdown()
                st.session_state.file_name = file_name
                st.subheader("âœ… ì—…ë¡œë“œ íŒŒì¼ ë¯¸ë¦¬ë³´ê¸°")
                st.dataframe(df, height=300, use_container_width=True)
            else: # PDF ë“± ê¸°íƒ€ íŒŒì¼
                st.session_state.file_name = file_name
                st.session_state.file_context = f"'{file_name}' íŒŒì¼ì´ ì—…ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤. ë‚´ìš©ì— ëŒ€í•´ ì§ˆë¬¸í•´ì£¼ì„¸ìš”."

        except Exception as e:
            st.error(f"íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            st.session_state.file_context = None
            st.session_state.file_name = None

    if st.session_state.file_name:
        if st.button("ğŸ”„ ì—…ë¡œë“œ íŒŒì¼ ì´ˆê¸°í™”", use_container_width=True):
            st.session_state.file_context = None
            st.session_state.file_name = None
            st.success("íŒŒì¼ì´ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤. ì¼ë°˜ ì§ˆë¬¸ ëª¨ë“œë¡œ ì „í™˜í•©ë‹ˆë‹¤.")
            time.sleep(1)
            st.rerun()

# --- ë©”ì¸ í™”ë©´ UI êµ¬ì„± ---
st.title("ì„¸ë´‡ì´ ğŸ¤–")
st.write("ë¶€ê°€ê°€ì¹˜ì„¸ ê´€ë ¨ ì§ˆë¬¸ì— ë‹µë³€í•´ ë“œë¦½ë‹ˆë‹¤. ì™¼ìª½ ì‚¬ì´ë“œë°”ì— íŒŒì¼ì„ ì˜¬ë ¤ íŠ¹ì • ë¬¸ì„œì— ëŒ€í•´ ì§ˆë¬¸í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤.")
st.write("---")

if st.session_state.file_name:
    st.info(f"ğŸ§¾ **'{st.session_state.file_name}' íŒŒì¼ì— ëŒ€í•´ ì§ˆë¬¸í•©ë‹ˆë‹¤.**")
else:
    st.info("ğŸ’¡ **ì¼ë°˜ ë¶€ê°€ê°€ì¹˜ì„¸ ì§ˆë¬¸ ëª¨ë“œì…ë‹ˆë‹¤.**")

# --- ì±„íŒ… ëŒ€í™” ê¸°ë¡ í‘œì‹œ ---
if not st.session_state.messages:
    st.session_state.messages.append({"role": "assistant", "content": "ì•ˆë…•í•˜ì„¸ìš”! ë¶€ê°€ê°€ì¹˜ì„¸ì— ëŒ€í•´ ê¶ê¸ˆí•œ ì ì„ ë¬¼ì–´ë³´ì„¸ìš”."})

for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.write(msg["content"])

# --- ì˜ˆì‹œ ì§ˆë¬¸ ë²„íŠ¼ ---
if len(st.session_state.messages) <= 1:
    st.write("**ì˜ˆì‹œ ì§ˆë¬¸:**")
    cols = st.columns(3)
    example_questions = ["ê°„ì´ê³¼ì„¸ì ë¶€ê°€ì„¸ëŠ”?", "ë§¤ì…ì„¸ì•¡ê³µì œë€?", "ì„¸ê¸ˆê³„ì‚°ì„œ ë°œê¸‰ì˜ë¬´"]
    
    if cols[0].button(example_questions[0], use_container_width=True):
        st.session_state.messages.append({"role": "user", "content": example_questions[0]})
        st.rerun()
    if cols[1].button(example_questions[1], use_container_width=True):
        st.session_state.messages.append({"role": "user", "content": example_questions[1]})
        st.rerun()
    if cols[2].button(example_questions[2], use_container_width=True):
        st.session_state.messages.append({"role": "user", "content": example_questions[2]})
        st.rerun()

# --- ì‚¬ìš©ì ì±„íŒ… ì…ë ¥ ---
if user_input := st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš” :)"):
    st.session_state.messages.append({"role": "user", "content": user_input})
    st.rerun()

# --- ì±—ë´‡ ì‘ë‹µ ìƒì„± ë¡œì§ (ìˆ˜ì •ëœ ì—ì´ì „íŠ¸ í˜¸ì¶œ) ---
if st.session_state.messages and st.session_state.messages[-1]["role"] == "user":
    user_prompt = st.session_state.messages[-1]["content"]
    
    # [ìˆ˜ì •] ëŒ€í™” ê¸°ë¡ì„ LangChain í˜•ì‹ìœ¼ë¡œ ë³€í™˜
    chat_history = [
        HumanMessage(content=msg["content"]) if msg["role"] == "user" 
        else AIMessage(content=msg["content"]) 
        for msg in st.session_state.messages[:-1]
    ]
    
    # [ìˆ˜ì •] íŒŒì¼ ì»¨í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥ í”„ë¡¬í”„íŠ¸ì— ì¶”ê°€
    final_input = user_prompt
    if st.session_state.file_context:
        final_input = f"""
[ì²¨ë¶€ëœ íŒŒì¼ ë‚´ìš©]
{st.session_state.file_context}
---
ìœ„ ì²¨ë¶€íŒŒì¼ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ì•„ë˜ ì§ˆë¬¸ì— ë‹µë³€í•´ ì£¼ì„¸ìš”.

[ì‚¬ìš©ì ì§ˆë¬¸]
{user_prompt}
"""

    # [ìˆ˜ì •] ì—ì´ì „íŠ¸ í˜¸ì¶œ ë°©ì‹
    agent_input = {
        "input": final_input,
        "chat_history": chat_history,
    }
    
    with st.chat_message("assistant"):
        with st.spinner("ìƒê° ì¤‘..."):
            response = agent_executor.invoke(agent_input)
            final_answer = response.get('output', 'ì˜¤ë¥˜: ë‹µë³€ì„ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.')
            
            st.session_state.messages.append({"role": "assistant", "content": final_answer})
            st.rerun()
